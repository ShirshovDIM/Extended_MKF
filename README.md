# Расширенный MKF

репозиторий для проекта по дисциплине "Численные методы оптимизации"

Участники:
 
[Ширшов Дмитрий (капитан)](https://github.com/ShirshovDIM) (также псевдоним ```MAINPROTOSPACE: SHIRSHOV DMITRY``` в коммитах)

[Кривошей Никита](https://github.com/nkrivoshey)

[Шамсутдинов Аяз](https://github.com/Ayazor)

## Пререквизиты
```shell
CMake >= 3.22
```

## Запуск
```shell
git clone https://github.com/ShirshovDIM/Extended_MKF.git
cd MKF
mkdir build && cd build
cmake ..
make -j8
```

- Запустить стандартный эксперимент для MKF
```shell
./main
```

## Технический отчет о проделанной работе

Помимо настроечных работ для штатной сборки и запуска приложения были проведены следующие действия, 

непосредственно затрагивающие логику исходного приложения с точки зрения оптимизации: 

- Задизайнен и реализован шаблон для введения новых алгоритмов, аппроксимирующих обратные матрицы (модули ```simple_vehicle_nkf.h```, ```simple_vehicle_nkf.cpp```). Шаблон учитывает типовой IO для того, чтобы оперировать внутри основного исполняемого модуля (в нашем случае endpoint находится в файле ```main.cpp```). 
- Реализованы алгоритмы BFGS, DFP и LBFGS для приближения обратной матрицы. 
- Реализован метод Ньютона-Шульца для приближения обратной матрицы 
- Проведена оптимизация утилизации памяти при формировании Kalman gain (метод ```update``` класса ```SimpleVehicleNKF```)
- Прочие доработки в рамках сборки и запуска проекта 

## Детализация технического отчета 

### Шаблонизация методов аппроксимации и прочие целевые доработки

В рамках доработки проекта реализована расширенная логика, позволяющую выбирать способ вычисления (точнее способ приближения) обратной матрицы, необходимой для расчёта Kalman gain в фильтре Калмана MKF.

Вместо того чтобы всегда использовать стандартный метод S.inverse() (который в рамках нашей реализации доработки называется DIRECT), была добавлена возможность применять n альтернативных аппроксимационных методов, написанных по шаблону в рамках договоренностей. В нашем случае это следующие алгоритмы: 
- BFGS
- DFP
- L‑BFGS
- NEWTON-SCHULTZ
- DIRECT

Для реализованных в нашем проекте алгоритмов происходит итеративный эксперимент с измерением скорости работы, стандартного отклонения и среднего ошибки при для каждого метода приближения. 

Конечные результаты измерений работы сохраняются в файл ```metrics_nkf.csv```

### Алгоритм Ньютона-Шульца (NEWTON-SCHULTZ)

**Постановка задачи:**

Дана матрица $S \in \mathbb{R}^{n \times n}$. Требуется найти матрицу $X$, такую что:

$
X \cdot S = I,
$

где $I$ — единичная матрица

**Итерационный процесс:**
1. Начальное приближение:
   
   $$
   X_0 = \frac{1}{\|S\|} \cdot I,
   $$
   
   где $\|S\|$ — норма матрицы $S$ (например, спектральная или Фробениуса)

2. Обновление на $k$-й итерации:
   
   $$
   X_{k+1} = X_k \cdot (2I - X_k \cdot S),
   $$
   
   что эквивалентно:
   
   $$
   X_{k+1} = X_k \cdot (I + R_k), \quad \text{где } R_k = I - X_k \cdot S
   $$

3. Условие остановки:
   
   $$
   \|R_k\| < \text{tol},
   $$
   
   где $\text{tol}$ — заданная точность, $R_k = I - X_k \cdot S$, $\|\cdot\|$ — матричная норма

### Оптимизация потребления памяти для Kalman gain 

Вычисление Kalman Gain
Ключевое вычисление в методе update — это коэффициент усиления Калмана $\mathbf{K}$. В стандартном подходе он вычисляется как:$$\mathbf{K} = \mathbf{\Sigma}_{xz} \cdot \mathbf{S}^{-1}$$
Для матриц $\mathbf{\Sigma}_{xz} \in \mathbb{R}^{3 \times 2}$ и $\mathbf{S} \in \mathbb{R}^{2 \times 2}$:

Вычисление $\mathbf{S}^{-1}$ требует обращения матрицы $2 \times 2$, что в общем случае имеет сложность $O(1)$, но может быть численно нестабильным.
Умножение $\mathbf{\Sigma}_{xz} \cdot \mathbf{S}^{-1}$ требует $3 \times 2 \times 2 = 12$ операций умножения.

Это вычисление может стать затратным для больших матриц или при частых вызовах метода update, особенно если $\mathbf{S}$ плохо обусловлена.

Мы применяем оптимизацию:

Диагональная аппроксимация $\mathbf{S}^{-1}$:Если $\mathbf{S}$ диагональна, то $\mathbf{S}^{-1}$ тоже диагональна, и её элементы вычисляются как:$$\mathbf{S}^{-1}(i,i) = \frac{1}{\mathbf{S}(i,i)}, \quad i = 0, 1$$

Это позволяет избежать полного обращения матрицы $\mathbf{S}$, снижая сложность с $O(1)$ до двух делений для $2 \times 2$.

Умножение с использованием спарс-матрицы:Вместо полного умножения $\mathbf{\Sigma}{xz} \cdot \mathbf{S}^{-1}$ мы итерируемся только по ненулевым элементам $\mathbf{\Sigma}{xz}$, представленной в спарс-формате:$$\mathbf{K}(i,j) = \mathbf{\Sigma}_{xz}(i,j) \cdot \mathbf{S}^{-1}(j,j)$$

Мы выполняем умножение только для ненулевых элементов, что снижает число операций.


Упрощение $\mathbf{S}^{-1}$: Вместо обращения матрицы $2 \times 2$ (что требует $O(1)$ операций, но может быть численно нестабильным), мы выполняем 2 деления.
Снижение числа умножений: В стандартном подходе умножение $\mathbf{\Sigma}{xz} \cdot \mathbf{S}^{-1}$ требует $3 \times 2 \times 2 = 12$ операций умножения. Если в $\mathbf{\Sigma}{xz}$ только 3 ненулевых элемента, мы выполняем только 3 умножения.
Теоретический выигрыш: Для больших матриц эффект был бы значительным. Например, для $\mathbf{S} \in \mathbb{R}^{100 \times 100}$ и $\mathbf{\Sigma}_{xz} \in \mathbb{R}^{200 \times 100}$ с 5% ненулевых элементов:
Обращение $\mathbf{S}$ требует $O(100^3) = O(10^6)$ операций, а диагональная аппроксимация — $O(100)$.
Умножение $\mathbf{\Sigma}_{xz} \cdot \mathbf{S}^{-1}$ требует $200 \times 100 \times 100 = 2 \times 10^6$ операций, а в спарс-формате — $200 \times 100 \times 0.05 = 1000$.


В нашей реализации эффект оптимизации минимален, так как:

Размеры матриц малы: $\mathbf{S} \in \mathbb{R}^{2 \times 2}$, $\mathbf{\Sigma}_{xz} \in \mathbb{R}^{3 \times 2}$. Стандартный метод и так выполняется быстро.

Реализованная оптимизация направлена на ускорение вычисления $\mathbf{K}$ за счёт использования свойств диагональности $\mathbf{S}$ и разреженности $\mathbf{\Sigma}{xz}$. Она снижает число операций умножения и упрощает обращение матрицы $\mathbf{S}$, что особенно эффективно для больших матриц. В текущей реализации эффект минимален из-за малых размеров матриц и плотности $\mathbf{\Sigma}{xz}$, но для больших систем выигрыш в производительности был бы значительным.


### Прочие нецелевые доработки

- доработана логика сборки проекта через CMake (```CMakeList.txt```)
- обновлено логирование основного эксперимента (модуль ```main.cpp```)
- обновлена логика построения графиков - добавлены дополнительные гистограммы для удобства в сравнительном анализе конечной доработки 
- расширена логика генерации синтетических данных
